# Comparing `tmp/haloop-0.0.4.tar.gz` & `tmp/haloop-0.0.5.tar.gz`

## Comparing `haloop-0.0.4.tar` & `haloop-0.0.5.tar`

### file list

```diff
@@ -1,17 +1,17 @@
--rw-r--r--   0        0        0      741 2020-02-02 00:00:00.000000 haloop-0.0.4/.github/workflows/release.yml
--rw-r--r--   0        0        0       22 2020-02-02 00:00:00.000000 haloop-0.0.4/ha/__about__.py
--rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 haloop-0.0.4/ha/__init__.py
--rw-r--r--   0        0        0     6215 2020-02-02 00:00:00.000000 haloop-0.0.4/ha/beam.py
--rw-r--r--   0        0        0     8168 2020-02-02 00:00:00.000000 haloop-0.0.4/ha/ctc.py
--rw-r--r--   0        0        0     2609 2020-02-02 00:00:00.000000 haloop-0.0.4/ha/data.py
--rw-r--r--   0        0        0     9970 2020-02-02 00:00:00.000000 haloop-0.0.4/ha/loop.py
--rw-r--r--   0        0        0     3725 2020-02-02 00:00:00.000000 haloop-0.0.4/ha/model.py
--rw-r--r--   0        0        0     9059 2020-02-02 00:00:00.000000 haloop-0.0.4/ha/rnnlm.py
--rw-r--r--   0        0        0     7830 2020-02-02 00:00:00.000000 haloop-0.0.4/ha/star.py
--rw-r--r--   0        0        0     3806 2020-02-02 00:00:00.000000 haloop-0.0.4/ha/symbol_tape.py
--rw-r--r--   0        0        0     2139 2020-02-02 00:00:00.000000 haloop-0.0.4/ha/transducer.py
--rw-r--r--   0        0        0     2058 2020-02-02 00:00:00.000000 haloop-0.0.4/ha/xen.py
--rw-r--r--   0        0        0       43 2020-02-02 00:00:00.000000 haloop-0.0.4/.gitignore
--rw-r--r--   0        0        0      395 2020-02-02 00:00:00.000000 haloop-0.0.4/README.md
--rw-r--r--   0        0        0     1462 2020-02-02 00:00:00.000000 haloop-0.0.4/pyproject.toml
--rw-r--r--   0        0        0     1240 2020-02-02 00:00:00.000000 haloop-0.0.4/PKG-INFO
+-rw-r--r--   0        0        0      741 2020-02-02 00:00:00.000000 haloop-0.0.5/.github/workflows/release.yml
+-rw-r--r--   0        0        0       22 2020-02-02 00:00:00.000000 haloop-0.0.5/ha/__about__.py
+-rw-r--r--   0        0        0        0 2020-02-02 00:00:00.000000 haloop-0.0.5/ha/__init__.py
+-rw-r--r--   0        0        0     6215 2020-02-02 00:00:00.000000 haloop-0.0.5/ha/beam.py
+-rw-r--r--   0        0        0     8168 2020-02-02 00:00:00.000000 haloop-0.0.5/ha/ctc.py
+-rw-r--r--   0        0        0     2609 2020-02-02 00:00:00.000000 haloop-0.0.5/ha/data.py
+-rw-r--r--   0        0        0     9970 2020-02-02 00:00:00.000000 haloop-0.0.5/ha/loop.py
+-rw-r--r--   0        0        0     3725 2020-02-02 00:00:00.000000 haloop-0.0.5/ha/model.py
+-rw-r--r--   0        0        0    11900 2020-02-02 00:00:00.000000 haloop-0.0.5/ha/rnnlm.py
+-rw-r--r--   0        0        0     7830 2020-02-02 00:00:00.000000 haloop-0.0.5/ha/star.py
+-rw-r--r--   0        0        0     5290 2020-02-02 00:00:00.000000 haloop-0.0.5/ha/symbol_tape.py
+-rw-r--r--   0        0        0     3552 2020-02-02 00:00:00.000000 haloop-0.0.5/ha/transducer.py
+-rw-r--r--   0        0        0     2058 2020-02-02 00:00:00.000000 haloop-0.0.5/ha/xen.py
+-rw-r--r--   0        0        0       43 2020-02-02 00:00:00.000000 haloop-0.0.5/.gitignore
+-rw-r--r--   0        0        0      378 2020-02-02 00:00:00.000000 haloop-0.0.5/README.md
+-rw-r--r--   0        0        0     1462 2020-02-02 00:00:00.000000 haloop-0.0.5/pyproject.toml
+-rw-r--r--   0        0        0     1223 2020-02-02 00:00:00.000000 haloop-0.0.5/PKG-INFO
```

### Comparing `haloop-0.0.4/.github/workflows/release.yml` & `haloop-0.0.5/.github/workflows/release.yml`

 * *Files identical despite different names*

### Comparing `haloop-0.0.4/ha/beam.py` & `haloop-0.0.5/ha/beam.py`

 * *Files identical despite different names*

### Comparing `haloop-0.0.4/ha/ctc.py` & `haloop-0.0.5/ha/ctc.py`

 * *Files identical despite different names*

### Comparing `haloop-0.0.4/ha/data.py` & `haloop-0.0.5/ha/data.py`

 * *Files identical despite different names*

### Comparing `haloop-0.0.4/ha/loop.py` & `haloop-0.0.5/ha/loop.py`

 * *Files identical despite different names*

### Comparing `haloop-0.0.4/ha/model.py` & `haloop-0.0.5/ha/model.py`

 * *Files identical despite different names*

### Comparing `haloop-0.0.4/ha/rnnlm.py` & `haloop-0.0.5/ha/rnnlm.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,18 +1,22 @@
 from pathlib import Path
 import argparse
-import sys
 
+from rich.console import Console
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
 import wandb
 
 from .symbol_tape import Vocabulary, tokenize_bytes, tokenize_chars, SymbolTape
 
+console = Console()
+def print(*args, flush=False, **kwargs):
+    console.log(*args, **kwargs)
+
 
 class LM(nn.Module):
     def __init__(self, vocab_size, emb_dim, hidden_dim, num_layers, dropout=0.0):
         super().__init__()
 
         self.num_classes = vocab_size
         self.hidden_dim = hidden_dim
@@ -20,21 +24,39 @@
 
         self.embedding = nn.Embedding(vocab_size, emb_dim)
         self.rnn = nn.LSTM(emb_dim, hidden_dim, num_layers, dropout=dropout)
         self.out_layer = nn.Linear(hidden_dim, vocab_size)
 
         self.out_layer.weight = self.embedding.weight
 
-    def forward(self, input, state):
+    def forward(self,
+                input, # (T, N)
+                state # ((L, N, H), (L, N, H))
+                ):
         emb = self.embedding(input)
+
         output, state = self.rnn(emb, state)
-        output = self.out_layer(output)
+        output = self.out_layer(output) # (T, N, V)
+
         output = output.view(-1, self.num_classes)
         return output, state
 
+    def forward_batch_first(self,
+                            input, # (N, T),
+                            state # ((L, N, H), (L, N, H))
+                            ):
+        emb = self.embedding(input)
+        emb = emb.transpose(0,1) # (T, N, H)
+
+        output, state = self.rnn(emb, state)
+        output = self.out_layer(output) # (T, N, V)
+        output = output.transpose(0,1) # (N, T, V)
+
+        return output, state
+
     def init_hidden(self, batch_size):
         weight = self.out_layer.weight
         h = weight.new_zeros(self.num_layers, batch_size, self.hidden_dim)
         c = weight.new_zeros(self.num_layers, batch_size, self.hidden_dim)
         return (h,c)
 
     def truncate_hidden(self, state):
@@ -52,19 +74,31 @@
             self.vocab = Vocabulary()
             self.vocab.load_state_dict(checkpoint['vocab'])
             extend_vocab = False
         else:
             extend_vocab = True
 
         if args.train:
-            if args.bytes_as_tokens:
-                self.data, self.vocab = tokenize_bytes(args.train, self.vocab, extend_vocab=extend_vocab)
-            else:
+            if args.vocab_from_data:
                 self.data, self.vocab = tokenize_chars(args.train, self.vocab, extend_vocab=extend_vocab)
-            self.batches = SymbolTape(self.data, args.batch_size, args.bptt_len, pad_id=0)
+            else:
+                self.data, self.vocab = tokenize_bytes(args.train, self.vocab, extend_vocab=extend_vocab)
+            self.dataset = SymbolTape(self.data, args.batch_size, args.bptt_len, pad_id=0)
+
+            self.batches = torch.utils.data.DataLoader(
+                self.dataset,
+                batch_size=1,
+                shuffle=False,
+                num_workers=args.num_workers,
+                prefetch_factor=2,
+                drop_last=False
+            )
+
+        if not self.vocab:
+            self.vocab = Vocabulary.bytes()
 
         vocab_size = len(self.vocab.id_to_string)
 
         self.model = LM(vocab_size=vocab_size,
                         emb_dim=args.rnn_size,
                         hidden_dim=args.rnn_size,
                         num_layers=args.num_layers,
@@ -74,47 +108,58 @@
         if args.init:
             self.model.load_state_dict(checkpoint['model'])
 
         self.optimizer = torch.optim.AdamW(params=self.model.parameters(), lr=args.lr, weight_decay=0.01)
         if args.init:
             self.optimizer.load_state_dict(checkpoint['optimizer'])
 
+        self.scaler = torch.cuda.amp.GradScaler()
+        if args.init:
+            self.scaler.load_state_dict(checkpoint['scaler'])
+
         self.loss = nn.CrossEntropyLoss(ignore_index=0)
 
         self.log_interval = args.log_interval
-        self.prompts = args.eval_prompts
+        if args.vocab_from_data:
+            self.prompts = args.complete
+        else:
+            self.prompts = [prompt.encode('utf-8') for prompt in args.complete]
         self.args = args
 
     def state_dict(self):
         return {
             'args': vars(self.args),
             'vocab': self.vocab.state_dict(),
             'model': self.model.state_dict(),
-            'optimizer': self.optimizer.state_dict()
+            'optimizer': self.optimizer.state_dict(),
+            'scaler': self.scaler.state_dict(),
         }
 
     def prepare_prompt(self, prompt):
         device = next(self.model.parameters()).device
 
-        prompt_list = [self.vocab.string_to_id[char] for char in prompt]
+        prompt_list = [self.vocab.string_to_id[char] if isinstance(char, str) else char for char in prompt]
         x = torch.tensor(prompt_list).to(device).unsqueeze(1).long()
 
         return x, self.model.init_hidden(1)
 
     @torch.inference_mode()
     def complete(self, prompt, steps=512, top_k=1):
         model = self.model
         model.eval()
 
         joiner = ''
         def cast(s):
+            nonlocal joiner
             if isinstance(s, int):
-                nonlocal joiner
                 joiner = b''
                 return s.to_bytes(1, 'big')
+            elif isinstance(s, bytes):
+                joiner = b''
+                return s
             return s
 
         out_list = []
         x, states = self.prepare_prompt(prompt)
 
         logits, states = model(x, states)
         prompt_logits = nn.functional.cross_entropy(logits[:-1], x[1:].view(-1), reduction='none').sum() / len(x[1:])
@@ -136,102 +181,131 @@
             logits[logits < v[:, [-1]]] = -float('Inf')
             probs = F.softmax(logits, dim=-1)
             ix = probs.multinomial(num_samples=1)
             out_list.append(cast(self.vocab.id_to_string[int(ix)]))
             x = ix
         return prompt_logits, joiner.join(out_list)
 
-    def train_one_epoch(self, epoch=0):
+    def train_one_epoch(self, epoch=0, step=0):
         model, batches = self.model, self.batches
-        optimizer, loss_fn = self.optimizer, self.loss
+        optimizer, scaler, loss_fn = self.optimizer, self.scaler, self.loss
 
         state = model.init_hidden(self.args.batch_size)
         model.train()
+        optimizer.zero_grad()
 
-        for step in range(len(batches)):
-            batch = batches[step].to(self.args.device).long()
-            model.train()
-            optimizer.zero_grad()
+        for i, batch in enumerate(batches, start=step):
+            batch = batch.to(self.args.device).long().squeeze(0)
             state = model.truncate_hidden(state)
 
             input = batch[:-1]
             target = batch[1:].reshape(-1)
 
-            batch_size = input.shape[1]
-            prev_batch_size = state[0].shape[1]
-            if batch_size != prev_batch_size:
-                h,c = state
-                state = h[:, :batch_size, :], c[:, :batch_size, :]
-            output, state = model(input, state)
-            loss = loss_fn(output, target)
-            loss.backward()
-            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1)
-            optimizer.step()
+            with torch.autocast(device_type='cuda', dtype=torch.float16):
+                output, state = model(input, state)
+                loss = loss_fn(output, target)
+
+            if torch.isnan(loss):
+                print(f'[{epoch + 1}, {i + 1:5d}], loss is nan, skipping batch', flush=True)
+                scaler.update()
+                continue
+
+            if torch.isinf(loss):
+                print(f'[{epoch + 1}, {i + 1:5d}], loss is inf, skipping batch, skipping scaler update', flush=True)
+                continue
 
-            if step % self.log_interval == 0:
-                outputs = []
-                for prompt in self.prompts:
-                    _, generated_text = self.complete(prompt, 128, top_k=self.args.top_k)
-                    outputs.append(prompt + generated_text)
-                print(f"epoch {epoch} step {step}/{len(batches)} loss: {loss.item():.3f} ppl: {loss.exp().item():.3f} grad_norm: {grad_norm.item():.3f} {'; '.join(outputs)}")
+            scaler.scale(loss).backward()
+            scaler.unscale_(optimizer)
+            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1)
+            if torch.isinf(grad_norm) or torch.isnan(grad_norm):
+                print(f'[{epoch + 1}, {i + 1:5d}], grad_norm is inf or nan, skipping batch', flush=True)
+                scaler.update()
+                optimizer.zero_grad(set_to_none=True)
+                continue
+
+            scaler.step(optimizer)
+            scaler.update()
+            optimizer.zero_grad(set_to_none=True)
+
+            if i % self.log_interval == 0:
+                _, outputs = self.evaluate()
+                print(f"epoch {epoch} step {i}/{len(batches)} loss: {loss.item():.3f} ppl: {loss.exp().item():.3f} grad_norm: {grad_norm.item():.3f} {'; '.join(outputs)}")
                 wandb.log({'train/loss': loss.item(),
                            'train/ppl': loss.exp().item(),
                            'train/lr': self.args.lr,
                            'train/epoch': epoch,
                            'train/grad_norm': grad_norm.item()})
+                model.train()
             else:
                 wandb.log({'train/loss': loss.item(),
                            'train/ppl': loss.exp().item(),
                            #'train/lr': scheduler.get_last_lr()[0],
                            'train/lr': self.args.lr,
                            'train/epoch': epoch,
                            'train/grad_norm': grad_norm.item()})
 
+            if self.args.max_steps >= 0 and i == self.args.max_steps:
+                break
+
+        return i+1
+
+    def evaluate(self):
+        prompt_scores = []
+        outputs = []
+        for prompt in self.prompts:
+            prompt_score, completion = self.complete(prompt, self.args.bptt_len, top_k=self.args.top_k)
+            if isinstance(completion, bytes):
+                outputs.append(str(prompt + completion, 'utf-8', errors='replace'))
+            else:
+                outputs.append(prompt + completion)
+            prompt_scores.append(prompt_score.item())
+        return prompt_scores, outputs
+
 
 def main():
     class Formatter(argparse.ArgumentDefaultsHelpFormatter,
                     argparse.MetavarTypeHelpFormatter):
         pass
 
-    parser = argparse.ArgumentParser(formatter_class=Formatter)
+    parser = argparse.ArgumentParser(description="hal trains recurrent language models", formatter_class=Formatter)
     parser.add_argument('--init', type=Path, help="Path to checkpoint to initialize from")
     parser.add_argument('--save', type=Path, default='rnnlm.pt', help="Path to save checkpoint to")
     parser.add_argument('--device', type=str, default='cuda:1', help='device')
-    parser.add_argument('--lr', default=0.0002, type=float, help='Adam learning rate')
+    parser.add_argument('--lr', default=0.002, type=float, help='Adam learning rate')
     parser.add_argument('--dropout', default=0, type=float, help='dropout rate')
     parser.add_argument('--epochs', default=1, type=int, help='number of training set iterations')
-    parser.add_argument('--batch-size', default=128, type=int, help='batch size')
+    parser.add_argument('--max-steps', default=-1, type=int, help='maximum number of training steps per epoch (useful for e.g. lr search)')
+    parser.add_argument('--batch-size', default=1280, type=int, help='batch size')
     parser.add_argument('--bptt-len', default=256, type=int, help='RNN window size')
-    parser.add_argument('--rnn-size', default=512, type=int, help='RNN width')
+    parser.add_argument('--rnn-size', default=2048, type=int, help='RNN width')
     parser.add_argument('--num-layers', default=1, type=int, help='RNN depth')
-    parser.add_argument('--bytes-as-tokens', action='store_true', help='use bytes as tokens')
+    parser.add_argument('--vocab-from-data', action='store_true', help='build character vocabulary from the data')
     parser.add_argument('--train', type=Path, help='Train model on this data')
-    parser.add_argument('--complete', type=str, help='complete this prompt')
     parser.add_argument('--top-k', type=int, default=1, help='top-k sampling')
     parser.add_argument('--log-interval', type=int, default=100, help="Number of batches between printing training status")
-    parser.add_argument('--eval-prompts', type=str, nargs='+', default=['\nа', '\nя'], help="Prompts to complete during evaluation")
+    #parser.add_argument('--complete, type=str, nargs='+', default=['\nа', '\nя'], help="Prompts to complete during evaluation")
+    parser.add_argument('--complete', type=str, nargs='+', default=['\nhello', '\nwhat '], help="Prompts to complete during evaluation")
+    parser.add_argument('--num-workers', type=int, default=8, help="Number of workers for data loading")
     args = parser.parse_args()
 
-    if not args.train and not args.complete:
-        parser.print_help()
-        print("\nPlease specify either --train or --complete", file=sys.stderr)
-        sys.exit(1)
-
     torch.manual_seed(3407)
 
     self = System(args)
 
     if args.train:
         print(args)
         wandb.init(project='rnnlm', config=args)
 
-        for epoch in range(args.epochs):
-            self.train_one_epoch(epoch=epoch)
+        step = 0
+        try:
+            for epoch in range(args.epochs):
+                step = self.train_one_epoch(epoch=epoch, step=step)
+                torch.save(self.state_dict(), args.save)
+        except KeyboardInterrupt:
+            print('interrupted, saving')
             torch.save(self.state_dict(), args.save)
 
-    if args.complete:
-        self.model.eval()
-        prompt_score, completion = self.complete("\n" + args.complete, 1024, top_k=args.top_k)
-        print(prompt_score.item(), args.complete + completion)
+    for prompt_score, completion in zip(*self.evaluate()):
+        print('{:.2f}'.format(prompt_score), completion)
 
 if __name__ == '__main__':
     main()
```

### Comparing `haloop-0.0.4/ha/star.py` & `haloop-0.0.5/ha/star.py`

 * *Files identical despite different names*

### Comparing `haloop-0.0.4/ha/xen.py` & `haloop-0.0.5/ha/xen.py`

 * *Files identical despite different names*

### Comparing `haloop-0.0.4/pyproject.toml` & `haloop-0.0.5/pyproject.toml`

 * *Files identical despite different names*

### Comparing `haloop-0.0.4/PKG-INFO` & `haloop-0.0.5/PKG-INFO`

 * *Files 15% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: haloop
-Version: 0.0.4
+Version: 0.0.5
 Summary: speech agent for 100 hours
 Project-URL: Documentation, https://github.com/proger/ha1#readme
 Project-URL: Issues, https://github.com/proger/ha1/issues
 Project-URL: Source, https://github.com/proger/ha1
 Author-email: Volodymyr Kyrylov <vol@wilab.org.ua>
 License-Expression: MIT
 Classifier: Development Status :: 4 - Beta
@@ -18,18 +18,18 @@
 Requires-Dist: g2p-en
 Requires-Dist: kaldialign
 Requires-Dist: rich
 Requires-Dist: torch
 Requires-Dist: torchaudio
 Description-Content-Type: text/markdown
 
-# ha1
+# haloop
 
-[![PyPI Version](https://img.shields.io/pypi/v/hecto-agent.svg)](https://pypi.python.org/pypi/hecto-agent)
+[![PyPI Version](https://img.shields.io/pypi/v/haloop.svg)](https://pypi.python.org/pypi/haloop)
 
-Hecto Agent provides `hac` program for acoustic model training and `hal` for language model. It is available on PyPI:
+Haloop provides `hac` program for acoustic model training and `hal` for language model. It is available on PyPI:
 
 ```
-pip install hecto-agent
+pip install haloop
 ```
 
 See [Speech Discrimination by Dynamic Programming, T. K. Vintsyuk (1968)](https://link.springer.com/article/10.1007/BF01074755)
```

